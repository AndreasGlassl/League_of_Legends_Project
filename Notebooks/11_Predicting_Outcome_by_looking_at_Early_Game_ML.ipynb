{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import re \n",
    "import time\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "challengergame_df = pd.read_csv('../Data/Match_Data/challenger_match.csv')\n",
    "challengergame_df2 = pd.read_csv('../Data/Match_Data/challenger_match_V2.csv')\n",
    "\n",
    "ingame_df = pd.read_pickle('../Data/Match_Data/match_data_version2.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chall_game = pd.concat([challengergame_df,challengergame_df2],axis = 0)\n",
    "chall_game_unique = chall_game.drop_duplicates('gameId')\n",
    "ingame_df['gameId'] = ingame_df['gameId'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chall_match = pd.merge(ingame_df,chall_game_unique[['gameId','accountId']], on = 'gameId', how = 'left')\\\n",
    "                                    .drop(columns=['status.message','status.status_code'])\\\n",
    "                                    .dropna(axis=0)\\\n",
    "                                    .reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "match_df = chall_match[chall_match[\"queueId\"]==420].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "champs = pd.read_csv(\"../Data/Champions_Items_Info/champions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparing_dataframe(df, lower:int, upper:int):\n",
    "    df_storage = pd.DataFrame()\n",
    "    for i in range(lower,upper):\n",
    "        \n",
    "        ''' Getting macro information on the game: \n",
    "            This is the ID of the game and the duration of the game.\n",
    "        '''\n",
    "        \n",
    "        gameId = df[\"gameId\"].iloc[i]\n",
    "        gameDuration = df[\"gameDuration\"].iloc[i]\n",
    "        \n",
    "        ''' \n",
    "        Now looking into the teams statistics, where we want to get information on \n",
    "        first blood, first tower, first dragon. If this is True for team \"Blue\", \n",
    "        the value will be set to 1, otherwise it will be set to 0\n",
    "        '''\n",
    "        \n",
    "        blueWins = np.where(df['teams'].iloc[i][0]['win']==\"Win\", 1, 0)\n",
    "        firstblood_blue = np.where(df['teams'].iloc[i][0]['firstBlood']==True,1,0)\n",
    "        firstTower_blue = np.where(df['teams'].iloc[i][0]['firstTower']==True,1,0)\n",
    "        firstDragon_blue = np.where(df['teams'].iloc[i][0]['firstDragon']==True,1,0)       \n",
    "        \n",
    "        '''\n",
    "        Now looking into the different participants\n",
    "        In there we want to get information on average gold/minute and exp/minute for the early game\n",
    "        '''\n",
    "        champion_list_blue = []\n",
    "        champion_list_red = []\n",
    "        \n",
    "        gold_per_minute_blue = 0\n",
    "        xp_per_minute_blue = 0\n",
    "        cs_per_minute_blue = 0\n",
    "        damage_taken_per_minute_blue = 0\n",
    "\n",
    "        gold_per_minute_red = 0\n",
    "        xp_per_minute_red = 0\n",
    "        cs_per_minute_red = 0\n",
    "        damage_taken_per_minute_red = 0\n",
    "        \n",
    "        for j in range(len(df[\"participants\"].iloc[i])):\n",
    "            if df[\"participants\"].iloc[i][j][\"teamId\"]==100:\n",
    "                champion_list_blue.append(df[\"participants\"].iloc[i][j][\"championId\"])\n",
    "                try:\n",
    "                    gpm = df[\"participants\"].iloc[i][j][\"timeline\"][\"goldPerMinDeltas\"][\"0-10\"]\n",
    "                except:\n",
    "                    gpm = 0\n",
    "                try:\n",
    "                    xpm = df[\"participants\"].iloc[i][j][\"timeline\"][\"xpPerMinDeltas\"][\"0-10\"]\n",
    "                except:\n",
    "                    xpm = 0\n",
    "                try:\n",
    "                    cspm = df[\"participants\"].iloc[i][j][\"timeline\"][\"creepsPerMinDeltas\"][\"0-10\"]\n",
    "                except:\n",
    "                    cspm = 0\n",
    "                try:\n",
    "                    dtpm = df[\"participants\"].iloc[i][j][\"timeline\"][\"damageTakenPerMinDeltas\"][\"0-10\"]\n",
    "                except:\n",
    "                    dtpm = 0\n",
    "                    \n",
    "                gold_per_minute_blue += gpm\n",
    "                xp_per_minute_blue += xpm\n",
    "                cs_per_minute_blue += cspm\n",
    "                damage_taken_per_minute_blue += dtpm \n",
    "            else:\n",
    "                champion_list_red.append(df[\"participants\"].iloc[i][j][\"championId\"])\n",
    "                try:\n",
    "                    gpm = df[\"participants\"].iloc[i][j][\"timeline\"][\"goldPerMinDeltas\"][\"0-10\"]\n",
    "                except:\n",
    "                    gpm = 0\n",
    "                try:\n",
    "                    xpm = df[\"participants\"].iloc[i][j][\"timeline\"][\"xpPerMinDeltas\"][\"0-10\"]\n",
    "                except:\n",
    "                    xpm = 0\n",
    "                try:\n",
    "                    cspm = df[\"participants\"].iloc[i][j][\"timeline\"][\"creepsPerMinDeltas\"][\"0-10\"]\n",
    "                except:\n",
    "                    cspm = 0\n",
    "                try:\n",
    "                    dtpm = df[\"participants\"].iloc[i][j][\"timeline\"][\"damageTakenPerMinDeltas\"][\"0-10\"]\n",
    "                except:\n",
    "                    dtpm = 0\n",
    "                    \n",
    "                gold_per_minute_red += gpm\n",
    "                xp_per_minute_red += xpm\n",
    "                cs_per_minute_red += cspm\n",
    "                damage_taken_per_minute_red += dtpm \n",
    "        \n",
    "                \n",
    "        global_result = [int(gameId), int(gameDuration), int(blueWins), int(firstblood_blue),\\\n",
    "                        int(firstTower_blue), int(firstDragon_blue)]\n",
    "        \n",
    "        champion_list = [champion_list_blue, champion_list_red]\n",
    "        \n",
    "        blue_data = [gold_per_minute_blue, xp_per_minute_blue,\\\n",
    "                     int(cs_per_minute_blue), int(damage_taken_per_minute_blue)]\n",
    "             \n",
    "        red_data = [int(gold_per_minute_red), int(xp_per_minute_red),\\\n",
    "                    int(cs_per_minute_red), int(damage_taken_per_minute_red)]\n",
    "        \n",
    "        all_data = np.array([global_result+ champion_list+ blue_data+red_data])\n",
    "        \n",
    "        columns_list = [\"gameId\", \"gameDuration\", \"blueWins\",\"First Blood\",\\\n",
    "                        \"First Tower\", \"First Dragon\",\"champion_list_blue\",\\\n",
    "                       \"champion_list_red\", \"gpm_blue\", \"xp_pm_blue\",\\\n",
    "                       \"cs_pm_blue\", \"dmg_taken_blue\", \"gpm_red\",\\\n",
    "                       \"xp_pm_red\", \"cs_pm_red\", \"dmg_taken_red\"]\n",
    "        \n",
    "        row_df = pd.DataFrame(all_data, columns = columns_list)\n",
    "        \n",
    "        df_storage = df_storage.append(row_df)\n",
    "    return df_storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processing_df(df, splitter=1):\n",
    "    prepared_df = pd.DataFrame()\n",
    "    stepsize = len(df)/splitter\n",
    "    for i in range(splitter):\n",
    "        lower = int(i*stepsize)\n",
    "        upper = int((i+1)*stepsize)\n",
    "        prepared_df = prepared_df.append(preparing_dataframe(df,lower,upper))\n",
    "        print(i)\n",
    "    return prepared_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "processed_df = processing_df(match_df,splitter=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = processed_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2000\n",
      "4000\n",
      "6000\n",
      "8000\n",
      "10000\n",
      "12000\n",
      "14000\n",
      "16000\n",
      "18000\n",
      "20000\n",
      "22000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(working_df)):\n",
    "    working_df[\"champion_list_blue\"].iloc[i] = [eval(champs[champs[\"key\"]==champion].iloc[0,2])\\\n",
    "                                                for champion in working_df[\"champion_list_blue\"].iloc[i]]\n",
    "    working_df[\"champion_list_red\"].iloc[i] = [eval(champs[champs[\"key\"]==champion].iloc[0,2])\\\n",
    "                                                for champion in working_df[\"champion_list_red\"].iloc[i]]\n",
    "    if i%2000==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameId</th>\n",
       "      <th>gameDuration</th>\n",
       "      <th>blueWins</th>\n",
       "      <th>First Blood</th>\n",
       "      <th>First Tower</th>\n",
       "      <th>First Dragon</th>\n",
       "      <th>champion_list_blue</th>\n",
       "      <th>champion_list_red</th>\n",
       "      <th>gpm_blue</th>\n",
       "      <th>xp_pm_blue</th>\n",
       "      <th>cs_pm_blue</th>\n",
       "      <th>dmg_taken_blue</th>\n",
       "      <th>gpm_red</th>\n",
       "      <th>xp_pm_red</th>\n",
       "      <th>cs_pm_red</th>\n",
       "      <th>dmg_taken_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4247263043</td>\n",
       "      <td>1323</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[Assassin, Mage], [Support, Mage], [Fighter, ...</td>\n",
       "      <td>[[Marksman, Support], [Marksman, Mage], [Mage]...</td>\n",
       "      <td>1237</td>\n",
       "      <td>1608.3</td>\n",
       "      <td>19</td>\n",
       "      <td>2370</td>\n",
       "      <td>1589</td>\n",
       "      <td>1837</td>\n",
       "      <td>22</td>\n",
       "      <td>2234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4247155821</td>\n",
       "      <td>1317</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Marksman], [Assassin, Fighter], [Support, Ma...</td>\n",
       "      <td>[[Marksman, Support], [Fighter, Marksman], [Ma...</td>\n",
       "      <td>1199.7</td>\n",
       "      <td>1674.1</td>\n",
       "      <td>22</td>\n",
       "      <td>1848</td>\n",
       "      <td>1339</td>\n",
       "      <td>1871</td>\n",
       "      <td>23</td>\n",
       "      <td>2267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4243963257</td>\n",
       "      <td>932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[[Marksman, Support], [Mage, Fighter], [Suppor...</td>\n",
       "      <td>[[Tank, Support], [Marksman], [Assassin, Mage]...</td>\n",
       "      <td>1311.7</td>\n",
       "      <td>1617.8</td>\n",
       "      <td>22</td>\n",
       "      <td>2099</td>\n",
       "      <td>1790</td>\n",
       "      <td>1982</td>\n",
       "      <td>23</td>\n",
       "      <td>2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4241678498</td>\n",
       "      <td>2098</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Tank, Fighter], [Mage, Support], [Marksman],...</td>\n",
       "      <td>[[Fighter, Tank], [Fighter], [Marksman], [Tank...</td>\n",
       "      <td>1318.4</td>\n",
       "      <td>1891.5</td>\n",
       "      <td>25</td>\n",
       "      <td>1963</td>\n",
       "      <td>1365</td>\n",
       "      <td>1876</td>\n",
       "      <td>25</td>\n",
       "      <td>1968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4241538868</td>\n",
       "      <td>2344</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[Marksman], [Fighter, Tank], [Marksman], [Mag...</td>\n",
       "      <td>[[Fighter, Tank], [Fighter, Tank], [Mage, Assa...</td>\n",
       "      <td>1497.2</td>\n",
       "      <td>1863.2</td>\n",
       "      <td>25</td>\n",
       "      <td>1626</td>\n",
       "      <td>1308</td>\n",
       "      <td>1789</td>\n",
       "      <td>19</td>\n",
       "      <td>1895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gameId gameDuration blueWins First Blood First Tower First Dragon  \\\n",
       "0  4247263043         1323        0           1           0            0   \n",
       "0  4247155821         1317        1           0           0            1   \n",
       "0  4243963257          932        0           0           0            0   \n",
       "0  4241678498         2098        0           0           0            1   \n",
       "0  4241538868         2344        1           1           1            1   \n",
       "\n",
       "                                  champion_list_blue  \\\n",
       "0  [[Assassin, Mage], [Support, Mage], [Fighter, ...   \n",
       "0  [[Marksman], [Assassin, Fighter], [Support, Ma...   \n",
       "0  [[Marksman, Support], [Mage, Fighter], [Suppor...   \n",
       "0  [[Tank, Fighter], [Mage, Support], [Marksman],...   \n",
       "0  [[Marksman], [Fighter, Tank], [Marksman], [Mag...   \n",
       "\n",
       "                                   champion_list_red gpm_blue xp_pm_blue  \\\n",
       "0  [[Marksman, Support], [Marksman, Mage], [Mage]...     1237     1608.3   \n",
       "0  [[Marksman, Support], [Fighter, Marksman], [Ma...   1199.7     1674.1   \n",
       "0  [[Tank, Support], [Marksman], [Assassin, Mage]...   1311.7     1617.8   \n",
       "0  [[Fighter, Tank], [Fighter], [Marksman], [Tank...   1318.4     1891.5   \n",
       "0  [[Fighter, Tank], [Fighter, Tank], [Mage, Assa...   1497.2     1863.2   \n",
       "\n",
       "  cs_pm_blue dmg_taken_blue gpm_red xp_pm_red cs_pm_red dmg_taken_red  \n",
       "0         19           2370    1589      1837        22          2234  \n",
       "0         22           1848    1339      1871        23          2267  \n",
       "0         22           2099    1790      1982        23          2181  \n",
       "0         25           1963    1365      1876        25          1968  \n",
       "0         25           1626    1308      1789        19          1895  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22711, 16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "champs_list = []\n",
    "for i in range(len(champs)):\n",
    "    [champs_list.append(tag) for tag in eval(champs[\"tags\"].loc[i]) if tag not in champs_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fighter', 'Tank', 'Mage', 'Assassin', 'Support', 'Marksman']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "champs_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Column to count each type of champion + the team "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in champs_list:\n",
    "    working_df[item+\"_blue\"]=0\n",
    "    working_df[item+\"_red\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreasglassl/opt/miniconda3/envs/backpack_banana/lib/python3.7/site-packages/pandas/core/indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(working_df)):\n",
    "    '''\n",
    "    First process the blue champion types:\n",
    "    '''\n",
    "    for j in range(len(working_df[\"champion_list_blue\"].iloc[i])):\n",
    "        if \"Fighter\" in working_df[\"champion_list_blue\"].iloc[i][j]:\n",
    "            working_df[\"Fighter_blue\"].iloc[i]+=1\n",
    "            \n",
    "        if \"Tank\" in working_df[\"champion_list_blue\"].iloc[i][j]:\n",
    "            working_df[\"Tank_blue\"].iloc[i]+=1\n",
    "            \n",
    "        if \"Mage\" in working_df[\"champion_list_blue\"].iloc[i][j]:\n",
    "            working_df[\"Mage_blue\"].iloc[i]+=1\n",
    "            \n",
    "        if \"Assasin\" in working_df[\"champion_list_blue\"].iloc[i][j]:\n",
    "            working_df[\"Assasin_blue\"].iloc[i]+=1\n",
    "            \n",
    "        if \"Support\" in working_df[\"champion_list_blue\"].iloc[i][j]:\n",
    "            working_df[\"Support_blue\"].iloc[i]+=1\n",
    "            \n",
    "        if \"Marksman\" in working_df[\"champion_list_blue\"].iloc[i][j]:\n",
    "            working_df[\"Marksman_blue\"].iloc[i]+=1\n",
    "            \n",
    "    '''\n",
    "    Then do the same with the red champions\n",
    "    '''\n",
    "    for j in range(len(working_df[\"champion_list_red\"].iloc[i])):\n",
    "        if \"Fighter\" in working_df[\"champion_list_red\"].iloc[i][j]:\n",
    "            working_df[\"Fighter_red\"].iloc[i]+=1\n",
    "            \n",
    "        if \"Tank\" in working_df[\"champion_list_red\"].iloc[i][j]:\n",
    "            working_df[\"Tank_red\"].iloc[i]+=1\n",
    "            \n",
    "        if \"Mage\" in working_df[\"champion_list_red\"].iloc[i][j]:\n",
    "            working_df[\"Mage_red\"].iloc[i]+=1\n",
    "            \n",
    "        if \"Assasin\" in working_df[\"champion_list_red\"].iloc[i][j]:\n",
    "            working_df[\"Assasin_red\"].iloc[i]+=1\n",
    "            \n",
    "        if \"Support\" in working_df[\"champion_list_red\"].iloc[i][j]:\n",
    "            working_df[\"Support_red\"].iloc[i]+=1\n",
    "            \n",
    "        if \"Marksman\" in working_df[\"champion_list_red\"].iloc[i][j]:\n",
    "            working_df[\"Marksman_red\"].iloc[i]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df = working_df.drop(columns=[\"champion_list_blue\",\"champion_list_red\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df=working_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df[\"First Blood\"]=working_df[\"First Blood\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df[\"First Tower\"]=working_df[\"First Tower\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df[\"First Dragon\"]=working_df[\"First Dragon\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_df[\"blueWins\"]=working_df[\"blueWins\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gameId             object\n",
       "gameDuration       object\n",
       "blueWins            int64\n",
       "First Blood         int64\n",
       "First Tower         int64\n",
       "First Dragon        int64\n",
       "Fighter_blue        int64\n",
       "Fighter_red         int64\n",
       "Tank_blue           int64\n",
       "Tank_red            int64\n",
       "Mage_blue           int64\n",
       "Mage_red            int64\n",
       "Assassin_blue       int64\n",
       "Assassin_red        int64\n",
       "Support_blue        int64\n",
       "Support_red         int64\n",
       "Marksman_blue       int64\n",
       "Marksman_red        int64\n",
       "gpm_blue          float64\n",
       "xp_pm_blue        float64\n",
       "cs_pm_blue        float64\n",
       "dmg_taken_blue    float64\n",
       "gpm_red           float64\n",
       "xp_pm_red         float64\n",
       "cs_pm_red         float64\n",
       "dmg_taken_red     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"gpm_blue\", \"xp_pm_blue\", \"cs_pm_blue\", \"dmg_taken_blue\",\\\n",
    "            \"gpm_red\", \"xp_pm_red\", \"cs_pm_red\", \"dmg_taken_red\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "scaled_fit = std.fit(working_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = pd.DataFrame(scaled_fit.transform(working_df[num_cols]), columns=num_cols)\n",
    "\n",
    "working_df = working_df.drop(columns=num_cols, axis=1)\n",
    "working_df = working_df.merge(scaled, left_index=True, right_index=True, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols=working_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols.remove(\"blueWins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols.remove(\"gameDuration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"blueWins\" in train_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"blueWins\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols.remove(\"gameId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(working_df, test_size=.2, random_state=3)\n",
    "\n",
    "train_X = train[train_cols].reset_index(drop=True)\n",
    "train_y = train[target_col].reset_index(drop=True)\n",
    "test_X = test[train_cols].reset_index(drop=True)\n",
    "test_y = test[target_col].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "First Blood         int64\n",
       "First Tower         int64\n",
       "First Dragon        int64\n",
       "Fighter_blue        int64\n",
       "Fighter_red         int64\n",
       "Tank_blue           int64\n",
       "Tank_red            int64\n",
       "Mage_blue           int64\n",
       "Mage_red            int64\n",
       "Assassin_blue       int64\n",
       "Assassin_red        int64\n",
       "Support_blue        int64\n",
       "Support_red         int64\n",
       "Marksman_blue       int64\n",
       "Marksman_red        int64\n",
       "gpm_blue          float64\n",
       "xp_pm_blue        float64\n",
       "cs_pm_blue        float64\n",
       "dmg_taken_blue    float64\n",
       "gpm_red           float64\n",
       "xp_pm_red         float64\n",
       "cs_pm_red         float64\n",
       "dmg_taken_red     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(train_X, train_y, test_X, test_y, model):\n",
    "    ml_model = model\n",
    "    ml_model.fit(train_X, train_y)\n",
    "    \n",
    "    predictions = ml_model.predict(test_X)\n",
    "    acc = accuracy_score(test_y, predictions)\n",
    "    \n",
    "    print(f\"Our model achieved an accuracy of {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model achieved an accuracy of 0.7541272287034999\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(train_X, train_y, test_X, test_y, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model achieved an accuracy of 0.6698217037200088\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(train_X, train_y, test_X, test_y, DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model achieved an accuracy of 0.74950473255558\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(train_X, train_y, test_X, test_y, RandomForestClassifier(n_estimators=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model achieved an accuracy of 0.7517059211974466\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(train_X, train_y, test_X, test_y, SGDClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\"Logistic Regression\": LogisticRegression(),\n",
    "          \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "          \"Random Forest\": RandomForestClassifier(n_estimators=100, n_jobs=-1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, X):\n",
    "    validation_results = cross_validate(model,\n",
    "                                        X,\n",
    "                                        train_y.values.ravel(),\n",
    "                                        cv=5,\n",
    "                                        scoring=\"balanced_accuracy\")\n",
    "    acc = validation_results[\"test_score\"].mean()\n",
    "    print(f\"Balanced Mean Accuracy Score: {acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, X):\n",
    "    for key, value in models.items():\n",
    "        print(f\"Model: {key}\")\n",
    "        validate_model(value, X)\n",
    "        print(\"--------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Balanced Mean Accuracy Score: 0.7595226434627441\n",
      "--------------\n",
      "\n",
      "Model: Decision Tree\n",
      "Balanced Mean Accuracy Score: 0.6675474410789921\n",
      "--------------\n",
      "\n",
      "Model: Random Forest\n",
      "Balanced Mean Accuracy Score: 0.7530283009947656\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(models, train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_rf = RFECV(models[\"Random Forest\"],\n",
    "                    cv=5,\n",
    "                    scoring=\"balanced_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(cv=5,\n",
       "      estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                       class_weight=None, criterion='gini',\n",
       "                                       max_depth=None, max_features='auto',\n",
       "                                       max_leaf_nodes=None, max_samples=None,\n",
       "                                       min_impurity_decrease=0.0,\n",
       "                                       min_impurity_split=None,\n",
       "                                       min_samples_leaf=1, min_samples_split=2,\n",
       "                                       min_weight_fraction_leaf=0.0,\n",
       "                                       n_estimators=100, n_jobs=-1,\n",
       "                                       oob_score=False, random_state=None,\n",
       "                                       verbose=0, warm_start=False),\n",
       "      min_features_to_select=1, n_jobs=None, scoring='balanced_accuracy',\n",
       "      step=1, verbose=0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_rf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector_rf.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['First Blood', 'First Tower', 'First Dragon', 'Fighter_blue',\n",
       "       'Fighter_red', 'Tank_blue', 'Tank_red', 'Mage_blue', 'Mage_red',\n",
       "       'Assassin_blue', 'Assassin_red', 'Support_blue', 'Support_red',\n",
       "       'Marksman_blue', 'Marksman_red', 'gpm_blue', 'xp_pm_blue', 'cs_pm_blue',\n",
       "       'dmg_taken_blue', 'gpm_red', 'xp_pm_red', 'cs_pm_red', 'dmg_taken_red'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X2 = train_X[train_X.columns[selector_rf.get_support()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Balanced Mean Accuracy Score: 0.7589173711811356\n",
      "--------------\n",
      "\n",
      "Model: Decision Tree\n",
      "Balanced Mean Accuracy Score: 0.6642456280503032\n",
      "--------------\n",
      "\n",
      "Model: Random Forest\n",
      "Balanced Mean Accuracy Score: 0.7532481107213082\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(models, train_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                    intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                    multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " 'Decision Tree': DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                        max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                        random_state=42, splitter='best'),\n",
       " 'Random Forest': RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                        criterion='gini', max_depth=None, max_features='auto',\n",
       "                        max_leaf_nodes=None, max_samples=None,\n",
       "                        min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                        min_samples_leaf=1, min_samples_split=2,\n",
       "                        min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                        n_jobs=-1, oob_score=False, random_state=None, verbose=0,\n",
       "                        warm_start=False)}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[\"Random Forest\"] = RandomForestClassifier(n_estimators=500, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector_rf2 = RFECV(models[\"Random Forest\"],\n",
    "                     cv=5,\n",
    "                     scoring=\"balanced_accuracy\")\n",
    "selector_rf.fit(train_X, train_y)\n",
    "train_X3 = train_X[train_X.columns[selector_rf.get_support()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Balanced Mean Accuracy Score: 0.7595226434627441\n",
      "--------------\n",
      "\n",
      "Model: Decision Tree\n",
      "Balanced Mean Accuracy Score: 0.6652910652937626\n",
      "--------------\n",
      "\n",
      "Model: Random Forest\n",
      "Balanced Mean Accuracy Score: 0.7552290348858917\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(models, train_X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_samples_split=2,\n",
       "                                              min_weight_fraction_leaf=0.0,\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False,\n",
       "                                              random_state=None, verbose=0,\n",
       "                                              warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [3, 10, None],\n",
       "                         'min_samples_leaf': [10, 30, 50, None],\n",
       "                         'n_estimators': [500, 1000]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='balanced_accuracy', verbose=0)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_rf = {\"n_estimators\": [500, 1000],\n",
    "                 \"criterion\": [\"gini\", \"entropy\"],\n",
    "                 \"bootstrap\": [True, False],\n",
    "                 \"max_depth\": [3, 10, None],\n",
    "                 \"min_samples_leaf\": [10, 30, 50, None]}\n",
    "\n",
    "tune_rf = GridSearchCV(RandomForestClassifier(),\n",
    "                       param_grid=param_grid_rf,\n",
    "                       cv=3,\n",
    "                       scoring=\"balanced_accuracy\",\n",
    "                       n_jobs=-1)\n",
    "\n",
    "tune_rf.fit(train_X3, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': 10,\n",
       " 'min_samples_leaf': 50,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Mean Accuracy Score: 0.7574859561798869\n"
     ]
    }
   ],
   "source": [
    "validate_model(RandomForestClassifier(**tune_rf.best_params_), train_X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_X3 = train_X[train_X.columns[selector_rf.get_support()]]\n",
    "rf_model = RandomForestClassifier(**tune_rf.best_params_)\n",
    "rf_model.fit(train_X3, train_y)\n",
    "\n",
    "test_X3 = test_X[test_X.columns[selector_rf.get_support()]]\n",
    "rf_pred = rf_model.predict(test_X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Balanced Mean Accuracy Score: 0.7595226434627441\n",
      "--------------\n",
      "\n",
      "Model: Decision Tree\n",
      "Balanced Mean Accuracy Score: 0.6652910652937626\n",
      "--------------\n",
      "\n",
      "Model: Random Forest\n",
      "Balanced Mean Accuracy Score: 0.7568802596136828\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(models, train_X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gameId             object\n",
    "gameDuration       object\n",
    "blueWins            int64\n",
    "First Blood         int64\n",
    "First Tower         int64\n",
    "First Dragon        int64\n",
    "Fighter_blue        int64\n",
    "Fighter_red         int64\n",
    "Tank_blue           int64\n",
    "Tank_red            int64\n",
    "Mage_blue           int64\n",
    "Mage_red            int64\n",
    "Assassin_blue       int64\n",
    "Assassin_red        int64\n",
    "Support_blue        int64\n",
    "Support_red         int64\n",
    "Marksman_blue       int64\n",
    "Marksman_red        int64\n",
    "gpm_blue          float64\n",
    "xp_pm_blue        float64\n",
    "cs_pm_blue        float64\n",
    "dmg_taken_blue    float64\n",
    "gpm_red           float64\n",
    "xp_pm_red         float64\n",
    "cs_pm_red         float64\n",
    "dmg_taken_red     float64\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\"Fighter_blue\", \"Fighter_red\", \"Tank_blue\",\"Tank_red\",\\\n",
    "            \"Mage_blue\",\"Mage_red\",\"Assassin_blue\",\"Assassin_red\",\\\n",
    "            \"Support_blue\",\"Support_red\", \"Marksman_blue\", \"Marksman_red\",\\\n",
    "            \"First Blood\", \"First Tower\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "scaled_fit = std.fit(working_df[num_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = pd.DataFrame(scaled_fit.transform(working_df[num_cols]), columns=num_cols)\n",
    "\n",
    "working_df = working_df.drop(columns=num_cols, axis=1)\n",
    "working_df = working_df.merge(scaled, left_index=True, right_index=True, how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols=working_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gameId             object\n",
       "gameDuration       object\n",
       "blueWins            int64\n",
       "First Dragon        int64\n",
       "gpm_blue          float64\n",
       "xp_pm_blue        float64\n",
       "cs_pm_blue        float64\n",
       "dmg_taken_blue    float64\n",
       "gpm_red           float64\n",
       "xp_pm_red         float64\n",
       "cs_pm_red         float64\n",
       "dmg_taken_red     float64\n",
       "Fighter_blue      float64\n",
       "Fighter_red       float64\n",
       "Tank_blue         float64\n",
       "Tank_red          float64\n",
       "Mage_blue         float64\n",
       "Mage_red          float64\n",
       "Assassin_blue     float64\n",
       "Assassin_red      float64\n",
       "Support_blue      float64\n",
       "Support_red       float64\n",
       "Marksman_blue     float64\n",
       "Marksman_red      float64\n",
       "First Blood       float64\n",
       "First Tower       float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "working_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cols = num_cols.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(working_df, test_size=.2, random_state=3)\n",
    "\n",
    "train_X = train[train_cols].reset_index(drop=True)\n",
    "train_y = train[target_col].reset_index(drop=True)\n",
    "test_X = test[train_cols].reset_index(drop=True)\n",
    "test_y = test[target_col].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model achieved an accuracy of 0.7536869909751266\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(train_X, train_y, test_X, test_y, LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Logistic Regression\n",
      "Balanced Mean Accuracy Score: 0.7595226737687868\n",
      "--------------\n",
      "\n",
      "Model: Decision Tree\n",
      "Balanced Mean Accuracy Score: 0.6672728683335798\n",
      "--------------\n",
      "\n",
      "Model: Random Forest\n",
      "Balanced Mean Accuracy Score: 0.7551739688065965\n",
      "--------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_models(models, train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
